# 深度学习

## 一、线性回归模型

**y=wx+b**

### 线性回归模型参数求解：

①穷举法

②最小二乘法

![image-20250822234208035](D:\postGrudate\postGrudate_study\img\0822\1.png)

![image-20250822234349128](D:\postGrudate\postGrudate_study\img\0822\2.png)

求极值，令偏导数为0

![image-20250823000022676](D:\postGrudate\postGrudate_study\img\0822\3.png)

**⭐③梯度下降法**

核心：找到正确的方向

![image-20250823155007428](D:\postGrudate\postGrudate_study\img\0822\4.png)

## 二、逻辑回归模型

逻辑回归算法的原理：

![image-20250823175710931](D:\postGrudate\postGrudate_study\img\0822\5.png)

![image-20250823175826547](D:\postGrudate\postGrudate_study\img\0822\6.png)

![image-20250823180845066](D:\postGrudate\postGrudate_study\img\0822\7.png)

(1)参数w更新（交叉熵损失函数）:

![image-20250823213700502](D:\postGrudate\postGrudate_study\img\0822\8.png)

（2）参数b更新：

![image-20250823214214768](D:\postGrudate\postGrudate_study\img\0822\9.png)

评价指标（P:postive,N:negative）：

![image-20250823215259499](D:\postGrudate\postGrudate_study\img\0822\10.png)

准确率：(TP+TN)/(TP+TN+FP+FN)

精确率：P = TP/(TP+FP)

召回率：召回=TP/(TP+FN)

F1值（精确率和召回率的调和均值）：2TP/(2TP+FP+FN)